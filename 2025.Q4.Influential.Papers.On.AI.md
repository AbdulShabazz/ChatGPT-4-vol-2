## OpenAI ChatGPT v1.2025.343 Influential.Papers.On.AI.md

**Q: Cite five new papers published on the subject of artificial learning this quarter which you consider influential and explain your reasons.**

**A:** Five potentially influential artificial learning papers published in Q4 2025 (October 1–December 31, 2025), with why:

1. Efficient Data Selection at Scale via Influence Distillation (NeurIPS 2025; presented December 3, 2025) ([NeurIPS][1])
   Reasons: introduces a mathematically grounded, optimizer-aware (Gradient Descent / Adam) sample-weighting framework for data selection, plus a landmark approximation for scalability; targets Large Language Model (LLM) fine-tuning efficiency directly (quality vs. cost). ([NeurIPS][1])

2. StreamBP: Memory-Efficient Exact Backpropagation for Long Sequence Training of LLMs (NeurIPS 2025; presented December 3, 2025) ([NeurIPS][2])
   Reasons: claims *exact* backpropagation with substantially reduced activation/logit memory via a sequence-dimension decomposition, enabling materially longer contexts than checkpointing (reported 2.8–5.5×), and includes a distributed variant; long-context training is a direct bottleneck for many frontier workloads. ([NeurIPS][2])

3. Thinkless: LLM Learns When to Think (NeurIPS 2025; presented December 3, 2025) ([NeurIPS][3])
   Reasons: formalizes “adaptive reasoning depth” as a learned policy (short-form vs. long-form) trained with Reinforcement Learning (RL), reporting large reductions in long-chain reasoning usage (50–90%) while maintaining benchmark performance; this directly attacks inference cost/latency. ([NeurIPS][3])

4. Controlling Thinking Speed in Reasoning Models (NeurIPS 2025; presented December 5, 2025) ([NeurIPS][4])
   Reasons: proposes test-time control of reasoning speed via a representation-space “steering vector” and difficulty estimation, aiming for an accuracy–token tradeoff without additional training; if robust, this is a general knob for deployment-time compute scaling. ([NeurIPS][4])

5. Reasoning with Sampling: Your Base Model is Smarter Than You Think (arXiv; submitted October 16, 2025) ([arXiv][5])
   Reasons: reframes improved reasoning as a *decoding/sampling* problem rather than exclusively a training problem, which—when it works—has immediate adoption potential because it can apply to existing pretrained models without retraining. ([arXiv][5])
```
[1]: https://neurips.cc/virtual/2025/poster/119164 "NeurIPS Poster Efficient Data Selection at Scale via Influence Distillation"
[2]: https://neurips.cc/virtual/2025/poster/119094 "NeurIPS Poster StreamBP: Memory-Efficient Exact Backpropagation for Long Sequence Training of LLMs"
[3]: https://neurips.cc/virtual/2025/poster/117232 "NeurIPS Poster Thinkless: LLM Learns When to Think"
[4]: https://neurips.cc/virtual/2025/poster/119132 "NeurIPS Poster Controlling Thinking Speed in Reasoning Models"
[5]: https://arxiv.org/abs/2510.14901?utm_source=chatgpt.com "Reasoning with Sampling: Your Base Model is Smarter ..."
```
